{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages and define helper functions and objects\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import math\n",
    "from sklearn.metrics import roc_curve, roc_auc_score  \n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "#Converts time string to float value\n",
    "def string_to_timestamp(date_string):\n",
    "    time_stamp = time.strptime(date_string, '%Y-%m-%d %H:%M:%S')\n",
    "    return time.mktime(time_stamp)\n",
    "\n",
    "#Helper objects for encoding the categorical data\n",
    "(issuercountry_set, txvariantcode_set, currencycode_set, shoppercountry_set, interaction_set,\n",
    "verification_set, accountcode_set, mail_id_set, ip_id_set, card_id_set) = [set() for _ in range(10)]\n",
    "(issuercountry_dict, txvariantcode_dict, currencycode_dict, shoppercountry_dict, interaction_dict,\n",
    "verification_dict, accountcode_dict, mail_id_dict, ip_id_dict, card_id_dict) = [{} for _ in range(10)]\n",
    "sm = SMOTE(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the data from the given csv\n",
    "def get_raw_data() : \n",
    "    ah = open('data_for_student_case.csv', 'r')\n",
    "    data = []\n",
    "    ah.readline()#skip first line\n",
    "    for line_ah in ah:\n",
    "        if line_ah.strip().split(',')[9]=='Refused':# remove the row with 'refused' label, since it's uncertain about fraud\n",
    "            continue\n",
    "        if 'na' in str(line_ah.strip().split(',')[14]).lower() or 'na' in str(line_ah.strip().split(',')[4].lower()):\n",
    "            continue\n",
    "        txtid =line_ah.strip().split(',')[0]\n",
    "        bookingdate = string_to_timestamp(line_ah.strip().split(',')[1])# date reported flaud\n",
    "        issuercountry = line_ah.strip().split(',')[2]#country code\n",
    "        issuercountry_set.add(issuercountry)\n",
    "        txvariantcode = line_ah.strip().split(',')[3]#type of card: visa/master\n",
    "        txvariantcode_set.add(txvariantcode)\n",
    "        issuer_id = float(line_ah.strip().split(',')[4])#bin card issuer identifier\n",
    "        amount = float(line_ah.strip().split(',')[5])#transaction amount in minor units\n",
    "        currencycode = line_ah.strip().split(',')[6]\n",
    "        currencycode_set.add(currencycode)\n",
    "        shoppercountry = line_ah.strip().split(',')[7]#country code\n",
    "        shoppercountry_set.add(shoppercountry)\n",
    "        interaction = line_ah.strip().split(',')[8]#online transaction or subscription\n",
    "        interaction_set.add(interaction)\n",
    "        if line_ah.strip().split(',')[9] == 'Chargeback':\n",
    "            label = 1#label fraud\n",
    "        else:\n",
    "            label = 0#label save\n",
    "        verification = line_ah.strip().split(',')[10]#shopper provide CVC code or not\n",
    "        verification_set.add(verification)\n",
    "        cvcresponse = int(line_ah.strip().split(',')[11])#0 = Unknown, 1=Match, 2=No Match, 3-6=Not checked\n",
    "        if cvcresponse > 2:\n",
    "            cvcresponse = 3\n",
    "        year_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').year\n",
    "        month_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').month\n",
    "        day_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').day\n",
    "        creationdate = str(year_info)+'-'+str(month_info)+'-'+str(day_info)#Date of transaction \n",
    "        creationdate_stamp = string_to_timestamp(line_ah.strip().split(',')[12])#Date of transaction-time stamp\n",
    "        accountcode = line_ah.strip().split(',')[13]#merchantâ€™s webshop\n",
    "        accountcode_set.add(accountcode)\n",
    "        mail_id = int(float(line_ah.strip().split(',')[14].replace('email','')))#mail\n",
    "        mail_id_set.add(mail_id)\n",
    "        ip_id = int(float(line_ah.strip().split(',')[15].replace('ip','')))#ip\n",
    "        ip_id_set.add(ip_id)\n",
    "        card_id = int(float(line_ah.strip().split(',')[16].replace('card','')))#card\n",
    "        card_id_set.add(card_id)\n",
    "        data.append([issuercountry, txvariantcode, issuer_id, amount, currencycode,\n",
    "                    shoppercountry, interaction, verification, cvcresponse, creationdate_stamp,\n",
    "                     accountcode, mail_id, ip_id, card_id, label, creationdate])\n",
    "    data = sorted(data, key = lambda k: k[-1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the raw data so one can apply ML to it \n",
    "def pre_process_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    #Iterate over all items and extract features and labels\n",
    "    for item in data:\n",
    "        feats = item[0:-2]\n",
    "        label = item[-2]\n",
    "        amount_GBP = conv_curr_2_GBP (item[4], item[3])\n",
    "        feats.append(amount_GBP)\n",
    "        x.append(feats)\n",
    "        y.append(label)\n",
    "    #Replace the categorical features to numeric representation     \n",
    "    x = encode_categorical_features(x)\n",
    "    #Put the data in np-arrays and scale\n",
    "    return (preprocessing.scale(np.array(x), axis=0),np.array(y))\n",
    "\n",
    "#Encodes the categorical features by mapping strings to integers \n",
    "def encode_categorical_features(x):\n",
    "    for item in list(issuercountry_set):\n",
    "        issuercountry_dict[item] = list(issuercountry_set).index(item)\n",
    "    for item in list(txvariantcode_set):\n",
    "        txvariantcode_dict[item] = list(txvariantcode_set).index(item)\n",
    "    for item in list(currencycode_set):\n",
    "        currencycode_dict[item] = list(currencycode_set).index(item)\n",
    "    for item in list(shoppercountry_set):\n",
    "        shoppercountry_dict[item] = list(shoppercountry_set).index(item)\n",
    "    for item in list(interaction_set):\n",
    "        interaction_dict[item] = list(interaction_set).index(item)\n",
    "    for item in list(verification_set):\n",
    "        verification_dict[item] = list(verification_set).index(item)\n",
    "    for item in list(accountcode_set):\n",
    "        accountcode_dict[item] = list(accountcode_set).index(item)\n",
    "    for item in x:\n",
    "        item[0] = issuercountry_dict[item[0]]\n",
    "        item[1] = txvariantcode_dict[item[1]]\n",
    "        item[4] = currencycode_dict[item[4]]\n",
    "        item[5] = shoppercountry_dict[item[5]]\n",
    "        item[6] = interaction_dict[item[6]]\n",
    "        item[7] = verification_dict[item[7]]\n",
    "        item[10] = accountcode_dict[item[10]]\n",
    "    return x\n",
    "\n",
    "#Convert currency to British Pounds\n",
    "def conv_curr_2_GBP (currencycode, amount):\n",
    "    rates = {'NZD':0.46, 'AUD':0.49, 'GBP':1, 'MXN':0.04, 'SEK':0.08}\n",
    "    rate = rates[currencycode]\n",
    "    return rate*amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot roc curve\n",
    "def plot_roc_curve(clf, y_test, x_test, name='Receiver operating characteristic'):\n",
    "    \n",
    "    # predict probabilities\n",
    "    probs = clf.predict_proba(x_test)  \n",
    "    # keep probabilities for the positive outcome only\n",
    "    probs = probs[:, 1]\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the ML algorithm using cross-validation\n",
    "def evaluate_classifier(x,y,clf):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    kf = KFold(n_splits=10)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        #Initialize training and test data\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #Resamples the training data using SMOTE\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "        #Fits classifier to training data\n",
    "        clf.fit(x_train, y_train)\n",
    "        #Predict data for testing data\n",
    "        y_predict = clf.predict(x_test)\n",
    "        #Enumerate results\n",
    "        for i in range(len(y_predict)):\n",
    "            if y_test[i]==1 and y_predict[i]==1:\n",
    "                TP += 1\n",
    "            if y_test[i]==0 and y_predict[i]==1:\n",
    "                FP += 1\n",
    "            if y_test[i]==1 and y_predict[i]==0:\n",
    "                FN += 1\n",
    "            if y_test[i]==0 and y_predict[i]==0:\n",
    "                TN += 1\n",
    "    tp_avg = TP/10\n",
    "    fp_avg = FP/10\n",
    "    fn_avg = FN/10\n",
    "    tn_avg = TN/10\n",
    "    \n",
    "    #Calculates the pe\n",
    "    acc = (TP+TN)/(TP+FP+TN+FN) #Accuracy\n",
    "    recall = TP/(TP+FN) #Recall\n",
    "    specif = TN / (FP + TN) #Specificity\n",
    "    prec = TP/(TP+FP) #Precision\n",
    "    fp_rate = FP/(FP+TN) #False Positive Rate\n",
    "    \n",
    "    print ('TP: '+ str(TP))\n",
    "    print ('FP: '+ str(FP))\n",
    "    print ('FN: '+ str(FN))\n",
    "    print ('TN: '+ str(TN))\n",
    "    print ('FP Rate : '+ str(fp_rate))\n",
    "    print('Accuracy:' + str(acc))\n",
    "    print('Recall:' + str(recall))\n",
    "    print('Specificity:' + str(specif))\n",
    "    print('Precision:' + str(prec))\n",
    "\n",
    "#Run the ML algorithm without cross validation and plots ROC curve\n",
    "def test_classifier(x,y,clf, use_PCA=False, name='Receiver operating characteristic'):\n",
    "    TP, FP, FN, TN = 0.0000001, 0.0000001, 0.0000001, 0.0000001\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)   \n",
    "    x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "   # print(x_train)\n",
    "    if use_PCA:\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(x_train)\n",
    "\n",
    "        x_train = pca.transform(x_train)\n",
    "        x_test = pca.transform(x_test)\n",
    "        \n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    for i in range(len(y_predict)):\n",
    "        if y_test[i]==1 and y_predict[i]==1:\n",
    "            TP += 1\n",
    "        if y_test[i]==0 and y_predict[i]==1:\n",
    "            FP += 1\n",
    "        if y_test[i]==1 and y_predict[i]==0:\n",
    "            FN += 1\n",
    "        if y_test[i]==0 and y_predict[i]==0:\n",
    "            TN += 1\n",
    "    acc = (TP+TN)/(TP+FP+TN+FN)\n",
    "    recall = TP/(TP+FN)\n",
    "    specif = TN / (FP + TN)\n",
    "    prec = TP/(TP+FP) \n",
    "    tp_rate = TP/(TP+FN)\n",
    "    fp_rate = FP/(FP+TN)\n",
    "    \n",
    "    plot_roc_curve(clf, y_test, x_test, name)\n",
    "    \n",
    "    print ('TP: '+ str(TP))\n",
    "    print ('FP: '+ str(FP))\n",
    "    print ('FN: '+ str(FN))\n",
    "    print ('TN: '+ str(TN))\n",
    "    \n",
    "    print ('TP Rate : '+ str(tp_rate))\n",
    "    print ('FP Rate : '+ str(fp_rate))\n",
    "\n",
    "    \n",
    "    print('Accuracy:' + str(acc))\n",
    "    print('Recall:' + str(recall))\n",
    "    print('Specificity:' + str(specif))\n",
    "    print('Precision:' + str(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "data = get_raw_data() #Get the data from the csv\n",
    "(x,y) = pre_process_data(data) #Transforms the data to representation suitable for Machine learning\n",
    "\n",
    "#Define Classifiers\n",
    "classifiers = []\n",
    "classifiers.append((neighbors.KNeighborsClassifier(n_neighbors=5, weights = 'distance'), \"Distance Weighed KNN\"))\n",
    "classifiers.append((AdaBoostClassifier(n_estimators=1000), \"AdaBoost Classifier\"))\n",
    "classifiers.append((RandomForestClassifier(n_estimators=1000), \"Random Forest Classifier\"))\n",
    "classifiers.append((BaggingClassifier(base_estimator= svm.SVC(kernel = 'rbf', gamma='auto'), max_samples=0.001, bootstrap=False, n_estimators=1000, verbose=0), \"Bagged SVM\"))\n",
    "classifiers.append((ExtraTreesClassifier(n_estimators=1000, max_depth=None,min_samples_split=2, random_state=0, criterion='entropy'), \"Extra Random Forest Classifier with entropy criterion\"))\n",
    "\n",
    "#Iterate over all classifiers\n",
    "for (clf, name) in classifiers:\n",
    "    print(name)\n",
    "    evaluate_classifier(x,y,clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
