{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages and define helper functions and objects\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "\n",
    "#Converts time string to float value\n",
    "def string_to_timestamp(date_string):\n",
    "    time_stamp = time.strptime(date_string, '%Y-%m-%d %H:%M:%S')\n",
    "    return time.mktime(time_stamp)\n",
    "\n",
    "#Helper objects for encoding the categorical data\n",
    "(issuercountry_set, txvariantcode_set, currencycode_set, shoppercountry_set, interaction_set,\n",
    "verification_set, accountcode_set, mail_id_set, ip_id_set, card_id_set) = [set() for _ in range(10)]\n",
    "(issuercountry_dict, txvariantcode_dict, currencycode_dict, shoppercountry_dict, interaction_dict,\n",
    "verification_dict, accountcode_dict, mail_id_dict, ip_id_dict, card_id_dict) = [{} for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the data from the given csv\n",
    "def get_raw_data() : \n",
    "    ah = open('data_for_student_case.csv', 'r')\n",
    "    data = []\n",
    "    ah.readline()#skip first line\n",
    "    for line_ah in ah:\n",
    "        if line_ah.strip().split(',')[9]=='Refused':# remove the row with 'refused' label, since it's uncertain about fraud\n",
    "            continue\n",
    "        if 'na' in str(line_ah.strip().split(',')[14]).lower() or 'na' in str(line_ah.strip().split(',')[4].lower()):\n",
    "            continue\n",
    "        bookingdate = string_to_timestamp(line_ah.strip().split(',')[1])# date reported flaud\n",
    "        issuercountry = line_ah.strip().split(',')[2]#country code\n",
    "        issuercountry_set.add(issuercountry)\n",
    "        txvariantcode = line_ah.strip().split(',')[3]#type of card: visa/master\n",
    "        txvariantcode_set.add(txvariantcode)\n",
    "        issuer_id = float(line_ah.strip().split(',')[4])#bin card issuer identifier\n",
    "        amount = float(line_ah.strip().split(',')[5])#transaction amount in minor units\n",
    "        currencycode = line_ah.strip().split(',')[6]\n",
    "        currencycode_set.add(currencycode)\n",
    "        shoppercountry = line_ah.strip().split(',')[7]#country code\n",
    "        shoppercountry_set.add(shoppercountry)\n",
    "        interaction = line_ah.strip().split(',')[8]#online transaction or subscription\n",
    "        interaction_set.add(interaction)\n",
    "        if line_ah.strip().split(',')[9] == 'Chargeback':\n",
    "            label = 1#label fraud\n",
    "        else:\n",
    "            label = 0#label save\n",
    "        verification = line_ah.strip().split(',')[10]#shopper provide CVC code or not\n",
    "        verification_set.add(verification)\n",
    "        cvcresponse = int(line_ah.strip().split(',')[11])#0 = Unknown, 1=Match, 2=No Match, 3-6=Not checked\n",
    "        if cvcresponse > 2:\n",
    "            cvcresponse = 3\n",
    "        year_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').year\n",
    "        month_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').month\n",
    "        day_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').day\n",
    "        creationdate = str(year_info)+'-'+str(month_info)+'-'+str(day_info)#Date of transaction \n",
    "        creationdate_stamp = string_to_timestamp(line_ah.strip().split(',')[12])#Date of transaction-time stamp\n",
    "        accountcode = line_ah.strip().split(',')[13]#merchantâ€™s webshop\n",
    "        accountcode_set.add(accountcode)\n",
    "        mail_id = int(float(line_ah.strip().split(',')[14].replace('email','')))#mail\n",
    "        mail_id_set.add(mail_id)\n",
    "        ip_id = int(float(line_ah.strip().split(',')[15].replace('ip','')))#ip\n",
    "        ip_id_set.add(ip_id)\n",
    "        card_id = int(float(line_ah.strip().split(',')[16].replace('card','')))#card\n",
    "        card_id_set.add(card_id)\n",
    "        data.append([issuercountry, txvariantcode, issuer_id, amount, currencycode,\n",
    "                    shoppercountry, interaction, verification, cvcresponse, creationdate_stamp,\n",
    "                     accountcode, mail_id, ip_id, card_id, label, creationdate])\n",
    "    data = sorted(data, key = lambda k: k[-1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the raw data so one can apply ML to it \n",
    "def pre_process_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for item in data:\n",
    "        x.append(item[0:-2])\n",
    "        y.append(item[-2])\n",
    "        \n",
    "    x = encode_categorical_features(x)\n",
    "    return (np.array(x),np.array(y))\n",
    "\n",
    "#Encode the categorical features by mapping strings to integers \n",
    "def encode_categorical_features(x):\n",
    "    for item in list(issuercountry_set):\n",
    "        issuercountry_dict[item] = list(issuercountry_set).index(item)\n",
    "    for item in list(txvariantcode_set):\n",
    "        txvariantcode_dict[item] = list(txvariantcode_set).index(item)\n",
    "    for item in list(currencycode_set):\n",
    "        currencycode_dict[item] = list(currencycode_set).index(item)\n",
    "    for item in list(shoppercountry_set):\n",
    "        shoppercountry_dict[item] = list(shoppercountry_set).index(item)\n",
    "    for item in list(interaction_set):\n",
    "        interaction_dict[item] = list(interaction_set).index(item)\n",
    "    for item in list(verification_set):\n",
    "        verification_dict[item] = list(verification_set).index(item)\n",
    "    for item in list(accountcode_set):\n",
    "        accountcode_dict[item] = list(accountcode_set).index(item)\n",
    "    for item in x:\n",
    "        item[0] = issuercountry_dict[item[0]]\n",
    "        item[1] = txvariantcode_dict[item[1]]\n",
    "        item[4] = currencycode_dict[item[4]]\n",
    "        item[5] = shoppercountry_dict[item[5]]\n",
    "        item[6] = interaction_dict[item[6]]\n",
    "        item[7] = verification_dict[item[7]]\n",
    "        item[10] = accountcode_dict[item[10]]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the ML algorithm using cross-validation\n",
    "def evaluate_classifier(x,y,clf):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    kf = KFold(n_splits=10)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_predict = clf.predict(x_test)\n",
    "        for i in range(len(y_predict)):\n",
    "            if y_test[i]==1 and y_predict[i]==1:\n",
    "                TP += 1\n",
    "            if y_test[i]==0 and y_predict[i]==1:\n",
    "                FP += 1\n",
    "            if y_test[i]==1 and y_predict[i]==0:\n",
    "                FN += 1\n",
    "            if y_test[i]==0 and y_predict[i]==0:\n",
    "                TN += 1\n",
    "    print ('TP: '+ str(TP/10))\n",
    "    print ('FP: '+ str(FP/10))\n",
    "    print ('FN: '+ str(FN/10))\n",
    "    print ('TN: '+ str(TN/10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0.0\n",
      "FP: 0.0\n",
      "FN: 34.5\n",
      "TN: 23635.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "data = get_raw_data()\n",
    "(x,y) = pre_process_data(data)\n",
    "clf = svm.LinearSVC()\n",
    "evaluate_classifier(x,y,clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
